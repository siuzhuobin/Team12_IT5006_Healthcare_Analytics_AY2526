# correlations page. 
# Used chatGPT to find out how to calculate correlations between nominal-nominal and ordinal-nominal 
# variables, and used chatGPT-generated functions for these correlations wholesale
import streamlit as st 
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from dbShared import load_data
from scipy.stats import chi2_contingency


# generated by ChatGPT for correlaton between two nominal variables, copied and pasted wholesale
def cramers_v(x: pd.Series, y: pd.Series) -> float:
    """
    Bias-corrected Cramér's V for two nominal variables (0..1).
    """
    table = pd.crosstab(x, y)
    if table.size == 0:
        return np.nan

    chi2, _, _, _ = chi2_contingency(table, correction=False)
    n = table.values.sum()
    if n == 0:
        return np.nan

    phi2 = chi2 / n
    r, k = table.shape
    # Bias correction (Bergsma & Wicher, 2013)
    phi2_corr = max(0, phi2 - (k-1)*(r-1)/(n-1)) if n > 1 else 0
    r_corr = r - (r-1)**2/(n-1) if n > 1 else r
    k_corr = k - (k-1)**2/(n-1) if n > 1 else k
    denom = min((k_corr-1), (r_corr-1))
    return np.sqrt(phi2_corr / denom) if denom > 0 else 0.0

# generated by ChatGPT for correlation between nominal and ordinal varibales, copied and pasted wholesale
def correlation_ratio(categories: pd.Series, values: pd.Series) -> float:
    """
    Correlation ratio (eta) of nominal categories explaining a numeric variable (0..1).
    η = sqrt( between-group variance / total variance )
    """
    valid = pd.DataFrame({"cat": categories, "val": values}).dropna()
    if valid.empty:
        return np.nan

    y = valid["val"].values
    groups = valid.groupby("cat")["val"]

    overall_mean = y.mean()
    n_total = len(y)

    # Between-group sum of squares
    ss_between = sum(len(g) * (g.mean() - overall_mean)**2 for _, g in groups)
    # Total sum of squares
    ss_total = ((y - overall_mean)**2).sum()

    if ss_total == 0:
        return 0.0  # no variation in numeric -> no relationship measurable
    return float(np.sqrt(ss_between / ss_total))


@st.cache_data
def feature_correlation_static_items():
    X, y, df = load_data()
    st.header("Feature Correlation Analysis")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    corr_matrix = df[numeric_cols].corr()
    
    # Visualize correlation heatmap
    
    plt.clf()
    plt.figure()
    plt.figure(figsize=(10, 8))
    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
    
    ax = sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,
                square=True, linewidths=0.5, cbar_kws={"shrink": .8})
    plt.title('Numerical-Numerical Feature Correlation Heatmap')

    st.pyplot(ax.get_figure())
    

    # some plumbing for conversion between ZB's and Jenny's codes 
    int_columns = numeric_cols
    
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    string_columns = categorical_cols
    
    # here we treat redamission as an ordinal variable where NO is interpreted as a 
    # readmission duration of infinity. We define the ordering of the non-numerical ordinal 
    # features here 
    ordinal_orders = {'age': ['[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)', '[50-60)', '[60-70)', '[70-80)', '[80-90)', '[90-100)'],
        'readmitted':['<30','>30','NO']}
    
    nominal_columns = categorical_cols
    # excluded encounter_id and patient_nbr as nominal features because of their large cardinalities 
    
    nominal_columns = [c for c in nominal_columns if not c in ["age","encounter_id","patient_nbr"]]

    corr_diabetes = df.copy()

    # generate coded features for non-numerical ordinal variables 
    for c in ordinal_orders:
        corr_diabetes[c] = pd.Categorical(df[c], categories=ordinal_orders[c], ordered=True)
        corr_diabetes[c + "_code"] = corr_diabetes[c].cat.codes
    ordinal_columns = int_columns + [c + "_code" for c in ordinal_orders]
    

    # adapted from ChatGPT for calculating nominal-nominal correlations 
    cm = pd.DataFrame(index=nominal_columns, columns=nominal_columns, dtype=float)
    for a in nominal_columns:
        for b in nominal_columns:
            cm.loc[a, b] = cramers_v(corr_diabetes[a], corr_diabetes[b])


    plt.clf()
    plt.figure()
    plt.figure(figsize=(10, 8))
    mask = np.triu(np.ones_like(cm, dtype=bool))
    ax = sns.heatmap(cm, mask=mask, annot=False, cmap='RdBu_r', center=0,
                square=True, linewidths=0.5, cbar_kws={"shrink": .8})
    plt.title('Nominal-Nominal Feature Correlation Heatmap')
    st.caption("Calculated as Cramer's V as per suggested by chatGPT for nominal-nominal correlations")
    st.pyplot(ax.get_figure())
    


    eta_mat = pd.DataFrame(index=nominal_columns, columns=ordinal_columns, dtype=float)
    for cat in nominal_columns:
        for num in ordinal_columns:
            eta_mat.loc[cat, num] = correlation_ratio(corr_diabetes[cat], corr_diabetes[num])

    plt.clf()
    plt.figure()
    plt.figure(figsize=(10, 8))

    ax = sns.heatmap(eta_mat, annot=False, cmap='RdBu_r', center=0,
                square=True, linewidths=0.5, cbar_kws={"shrink": .8})
    plt.title('Nominal-Ordinal Feature Correlation Heatmap')
    st.caption("Calculated as $\eta$ correlation ratio as suggested by chatGPT")
    st.pyplot(ax.get_figure())
    
    






feature_correlation_static_items()

